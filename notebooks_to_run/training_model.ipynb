{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training Notebook (NovaSBE X GregoryAI)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Description of the image](../images/train_tune_pipeline_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lnpg1\\anaconda3\\envs\\gregoryai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the parent directory of code_utils to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from code_utils.text_utils import *  # Import everything from text_utils.py\n",
    "from code_utils.model_utils.LSTM_algorithm_utils import *  \n",
    "from code_utils.model_utils.BERT_algorithm_utils import *  \n",
    "from code_utils.model_utils.LGBM_algorithm_utils import *  \n",
    "from code_utils.model_utils.classify_model_choose import *\n",
    "from code_utils.download_utils import * \n",
    "from code_utils.pseudo_utils.utils_pseudo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the previous data\n",
    "old_articles_path = '..\\\\data\\\\articles_08-06-2024_14h13m04s.csv'\n",
    "url = 'https://api.gregory-ms.com/articles/?format=json'\n",
    "fetch_all_articles(url, old_articles_path, 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lnpg1\\Desktop\\NOVASBE\\GREGORY_AI\\Pi\\GregoryAIxNovaSBE\\code_utils\\text_utils.py:220: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[label_column] = data[label_column].apply(lambda x: 1 if x is True else (0 if x is False else 'unlabeled'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text_clean</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283515</th>\n",
       "      <td>prevalence stress urinary incontinence urge ur...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283512</th>\n",
       "      <td>radiologic lag brain mri lesion dynamics attac...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283510</th>\n",
       "      <td>motor function multiple sclerosis assessed nav...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283508</th>\n",
       "      <td>additive value complementing diagnostic idiopa...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283507</th>\n",
       "      <td>australian headache epidemiology data ahead pi...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text_clean   relevant\n",
       "article_id                                                              \n",
       "283515      prevalence stress urinary incontinence urge ur...  unlabeled\n",
       "283512      radiologic lag brain mri lesion dynamics attac...  unlabeled\n",
       "283510      motor function multiple sclerosis assessed nav...  unlabeled\n",
       "283508      additive value complementing diagnostic idiopa...  unlabeled\n",
       "283507      australian headache epidemiology data ahead pi...  unlabeled"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.path.join('../data/2024-05-07', # choose the day folder intended to use \n",
    "                            'train_articles.csv')\n",
    "\n",
    "# additional step to ensure consistency in the index column formating as article_id\n",
    "articles_df = pd.read_csv(dataset_path)\n",
    "\n",
    "# if the first column is not article_id, remove that first column\n",
    "\n",
    "if articles_df.columns[0] != 'article_id':\n",
    "    articles_df = articles_df.drop(columns=articles_df.columns[0])\n",
    "\n",
    "articles_clean_df = load_and_format_dataset(dataset_path, text_cleaning_pd_series)\n",
    "\n",
    "articles_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevant\n",
       "unlabeled    21676\n",
       "0             1267\n",
       "1              952\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_clean_df.relevant.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Split into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's divide thr articles_clean_df into labelled and unlabelled data\n",
    "\n",
    "unlabelled_df = articles_clean_df[articles_clean_df.relevant == 'unlabeled']\n",
    "labelled_df = articles_clean_df[articles_clean_df.relevant != 'unlabeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set distribution:\n",
      "relevant\n",
      "0    0.571153\n",
      "1    0.428847\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation set distribution:\n",
      "relevant\n",
      "0    0.570571\n",
      "1    0.429429\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set distribution:\n",
      "relevant\n",
      "0    0.570571\n",
      "1    0.429429\n",
      "Name: proportion, dtype: float64\n",
      "Number of articles in the training set: 1553\n",
      "Number of articles in the validation set: 333\n",
      "Number of articles in the test set: 333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "relevant_column = 'relevant'\n",
    "\n",
    "# First split: 85% train_val and 15% test\n",
    "train_val_df, test_df = train_test_split(\n",
    "    labelled_df,\n",
    "    test_size=0.15,\n",
    "    stratify=labelled_df[relevant_column],\n",
    "    random_state=69\n",
    ")\n",
    "\n",
    "# Second split: ~88.235% train and ~11.765% val from train_val_df\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=0.1765,  # 0.1765 * 0.85 â‰ˆ 0.15 of the original dataset\n",
    "    stratify=train_val_df[relevant_column],\n",
    "    random_state=69\n",
    ")\n",
    "\n",
    "# Verifying the splits\n",
    "print(\"Train set distribution:\")\n",
    "print(train_df[relevant_column].value_counts(normalize=True))\n",
    "print(\"\\nValidation set distribution:\")\n",
    "print(val_df[relevant_column].value_counts(normalize=True))\n",
    "print(\"\\nTest set distribution:\")\n",
    "print(test_df[relevant_column].value_counts(normalize=True))\n",
    "\n",
    "# Check the number of articles in each set\n",
    "print(f\"Number of articles in the training set: {len(train_df)}\")\n",
    "print(f\"Number of articles in the validation set: {len(val_df)}\")\n",
    "print(f\"Number of articles in the test set: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pseudo Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you may choose to perform the Pseudo-Labelling task: \n",
    "\n",
    "Self-Training with a Traditional ML model (in this example we have LogisticRegression but you can test with others) \n",
    "\n",
    "Co-training approach (that is a diferent type of pseudolabelling that uses a combination of two traditional machine learning models), \n",
    "\n",
    "Or the BERT model uncased.\n",
    "\n",
    "Our recomendation, to achieve best results, is BERT, but we understand it can be computer intensive and tricky to run.\n",
    "Below you have the different sections for the different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose max_lenght for BERT\n",
    "\n",
    "max_len = 128 # as said in the report, optimal would be 400, but here we had to choose 128 for computational reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = create_bert_uncased_model(max_len = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lnpg1\\AppData\\Local\\Temp\\ipykernel_22324\\2759835317.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labelled_df['text_processed'] = labelled_df['full_text_clean']\n",
      "C:\\Users\\lnpg1\\AppData\\Local\\Temp\\ipykernel_22324\\2759835317.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabelled_df['text_processed'] = unlabelled_df['full_text_clean']\n"
     ]
    }
   ],
   "source": [
    "labelled_df['text_processed'] = labelled_df['full_text_clean']\n",
    "unlabelled_df['text_processed'] = unlabelled_df['full_text_clean']\n",
    "train_df['text_processed'] = train_df['full_text_clean']\n",
    "val_df['text_processed'] = val_df['full_text_clean']\n",
    "test_df['text_processed'] = test_df['full_text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_train_df = train_df[['text_processed', 'relevant']]\n",
    "val_df_pseudo = val_df[['text_processed', 'relevant']]\n",
    "unlabelled_data_pseudo = unlabelled_df[['text_processed']]\n",
    "\n",
    "labelled_train_df, X_val, y_val, y_pred_val = bert_iterative_training(\n",
    "    model=bert_model,\n",
    "    tokenizer=tokenizer,\n",
    "    unlabelled_data_pseudo=unlabelled_data_pseudo,\n",
    "    labelled_train_df=labelled_train_df,\n",
    "    val_df_pseudo=val_df_pseudo,\n",
    "    max_len=max_len,\n",
    "    confidence_threshold=0.9,\n",
    "    max_iterations=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Using Traditional ML + vectorizer (Self-Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Using Co-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model and Store Model Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, here you may choose from different options to train the data:\n",
    "\n",
    "1 - BERT (Pubmed)\n",
    "\n",
    "2 - LSTM\n",
    "\n",
    "3 - LGBM (Tfidf)\n",
    "\n",
    "Our recomendation, to achieve best results, is BERT again, but we understand it can be computer intensive and tricky to run.\n",
    "Below you have the different sections for the different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Show Model Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gregoryai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
